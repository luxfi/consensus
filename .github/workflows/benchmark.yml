name: Benchmark Performance

on:
  # Run benchmarks on push to main
  push:
    branches: [main]
  # Run benchmarks on PRs
  pull_request:
    branches: [main]
  # Allow manual trigger
  workflow_dispatch:
  # Run nightly at 2 AM UTC
  schedule:
    - cron: '0 2 * * *'

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          cache: true

      - name: Get dependencies
        run: go mod download

      - name: Build benchmark tools
        run: |
          make zmq-bench || echo "zmq-bench build skipped"

      - name: Run ZeroMQ benchmarks
        run: |
          echo "## ZeroMQ Transport Benchmarks" | tee zmq-benchmark.md
          echo "" | tee -a zmq-benchmark.md
          echo "### Test Environment" | tee -a zmq-benchmark.md
          echo "- **Date**: $(date -u)" | tee -a zmq-benchmark.md
          echo "- **Commit**: ${{ github.sha }}" | tee -a zmq-benchmark.md
          echo "- **Go Version**: $(go version)" | tee -a zmq-benchmark.md
          echo "" | tee -a zmq-benchmark.md
          echo "### Results" | tee -a zmq-benchmark.md
          echo '```' | tee -a zmq-benchmark.md
          cd networking/zmq4
          go test -bench=. -benchmem -benchtime=30s -run=^$ -v 2>&1 | tee -a ../../zmq-benchmark.md
          cd ../..
          echo '```' | tee -a zmq-benchmark.md

      - name: Run consensus benchmarks
        run: |
          echo "" | tee -a consensus-benchmark.md
          echo "## Consensus Algorithm Benchmarks" | tee -a consensus-benchmark.md
          echo "" | tee -a consensus-benchmark.md
          echo "### Test Environment" | tee -a consensus-benchmark.md
          echo "- **Date**: $(date -u)" | tee -a consensus-benchmark.md
          echo "- **Commit**: ${{ github.sha }}" | tee -a consensus-benchmark.md
          echo "" | tee -a consensus-benchmark.md
          echo "### Results" | tee -a consensus-benchmark.md
          echo '```' | tee -a consensus-benchmark.md
          go test -bench=. -benchmem -benchtime=30s -run=^$ ./benchmark/... 2>&1 | tee -a consensus-benchmark.md
          echo '```' | tee -a consensus-benchmark.md

      - name: Run ZMQ consensus integration benchmarks
        run: |
          echo "" | tee -a zmq-consensus-benchmark.md
          echo "## ZMQ Consensus Integration Benchmarks" | tee -a zmq-consensus-benchmark.md
          echo "" | tee -a zmq-consensus-benchmark.md
          echo "### Multi-Validator Network Tests" | tee -a zmq-consensus-benchmark.md
          echo '```' | tee -a zmq-consensus-benchmark.md
          go test -bench=BenchmarkPhotonConsensusWithZMQ -benchmem -benchtime=10s -run=^$ ./benchmark/... 2>&1 | tee -a zmq-consensus-benchmark.md
          go test -bench=BenchmarkPulseConsensusWithZMQ -benchmem -benchtime=10s -run=^$ ./benchmark/... 2>&1 | tee -a zmq-consensus-benchmark.md
          go test -bench=BenchmarkWaveConsensusWithZMQ -benchmem -benchtime=10s -run=^$ ./benchmark/... 2>&1 | tee -a zmq-consensus-benchmark.md
          echo '```' | tee -a zmq-consensus-benchmark.md
          echo "" | tee -a zmq-consensus-benchmark.md
          echo "### Consensus Scalability Tests" | tee -a zmq-consensus-benchmark.md
          echo '```' | tee -a zmq-consensus-benchmark.md
          go test -bench=BenchmarkConsensusScalability -benchmem -benchtime=5s -run=^$ -short ./benchmark/... 2>&1 | tee -a zmq-consensus-benchmark.md
          echo '```' | tee -a zmq-consensus-benchmark.md

      - name: Run standalone ZMQ benchmark tool
        run: |
          echo "" | tee -a zmq-bench-tool.md
          echo "## Standalone ZMQ Benchmark Tool Results" | tee -a zmq-bench-tool.md
          echo "" | tee -a zmq-bench-tool.md
          
          # Get CPU count for optimal node placement
          CPU_COUNT=$(nproc || sysctl -n hw.ncpu || echo 4)
          echo "System has $CPU_COUNT CPU cores" | tee -a zmq-bench-tool.md
          echo "" | tee -a zmq-bench-tool.md
          
          # Test with different node counts and optimized parameters
          for NODES in 10 100 1000; do
            echo "### Multi-Validator Consensus ($NODES nodes)" | tee -a zmq-bench-tool.md
            echo "Parameters: batch=4096, interval=5ms, rounds=100" | tee -a zmq-bench-tool.md
            echo '```' | tee -a zmq-bench-tool.md
            ./bin/zmq-bench -nodes $NODES -batch 4096 -interval 5ms -rounds 100 2>&1 | grep -E "^ðŸ“Š|Nodes:|Duration:|TPS:|Throughput:|Message rate:|latency:" | tee -a zmq-bench-tool.md || true
            echo '```' | tee -a zmq-bench-tool.md
            echo "" | tee -a zmq-bench-tool.md
          done
          
          # High-performance test with nodes per core
          MAX_NODES=$((CPU_COUNT * 2))
          echo "### High-Performance Test ($MAX_NODES nodes, 2 per core)" | tee -a zmq-bench-tool.md
          echo "Parameters: batch=8192, interval=1ms, rounds=50" | tee -a zmq-bench-tool.md
          echo '```' | tee -a zmq-bench-tool.md
          ./bin/zmq-bench -nodes $MAX_NODES -batch 8192 -interval 1ms -rounds 50 2>&1 | grep -E "^ðŸ“Š|Nodes:|Duration:|TPS:|Throughput:|Message rate:|latency:" | tee -a zmq-bench-tool.md || true
          echo '```' | tee -a zmq-bench-tool.md

      - name: Combine results
        run: |
          cat zmq-benchmark.md consensus-benchmark.md zmq-consensus-benchmark.md zmq-bench-tool.md > benchmark-results.md
          echo "" >> benchmark-results.md
          echo "---" >> benchmark-results.md
          echo "" >> benchmark-results.md
          echo "### Benchmark Summary" >> benchmark-results.md
          echo "" >> benchmark-results.md
          echo "- **ZMQ Transport**: Pure transport layer performance" >> benchmark-results.md
          echo "- **Consensus Algorithms**: Individual algorithm benchmarks" >> benchmark-results.md
          echo "- **ZMQ + Consensus**: Full integration with multiple validators" >> benchmark-results.md
          echo "- **Standalone Tool**: Real-world network simulation" >> benchmark-results.md
          echo "" >> benchmark-results.md
          echo "To compare with previous results, see the [benchmark history](https://github.com/${{ github.repository }}/actions/workflows/benchmark.yml)" >> benchmark-results.md

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: |
            benchmark-results.md
            zmq-benchmark.md
            consensus-benchmark.md
            zmq-consensus-benchmark.md
            zmq-bench-tool.md
          retention-days: 90

      - name: Display results in summary
        run: |
          cat benchmark-results.md >> $GITHUB_STEP_SUMMARY

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = fs.readFileSync('benchmark-results.md', 'utf8');
            
            // Find existing comment
            const comments = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo
            });
            
            const botComment = comments.data.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('## ZeroMQ Transport Benchmarks')
            );
            
            const body = `${results}\n\n<sub>ðŸ¤– Posted by GitHub Actions Benchmark Bot</sub>`;
            
            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                comment_id: botComment.id,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }

      - name: Store benchmark results for comparison
        if: github.ref == 'refs/heads/main'
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'go'
          output-file-path: benchmark-results.md
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: true
          fail-on-alert: false
          alert-comment-cc-users: '@${{ github.repository_owner }}'